{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGwWjLIcvhHSMkHaLhvvp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunpav/Chatbot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF Chatbot\n",
        "---\n",
        "Able to tell the current time and respond to Hello, or Goodbye."
      ],
      "metadata": {
        "id": "NlFH6J5hzaPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "#Importing the questions and answers dataset from the class repo\n",
        "  #Tutorial dataset doesn't work for me...\n",
        "\n",
        "questions = [\n",
        "    'How are you?',\n",
        "    'What is your name?',\n",
        "    'What is TensorFlow?',\n",
        "    'Do you like Python?',\n",
        "    'What is your favorite color?',\n",
        "    'Tell me a joke.',\n",
        "    'What time is it?',\n",
        "    'Do you know Siri?',\n",
        "    'Can you play music?',\n",
        "    'How do I make tea?',\n",
        "    'What’s the weather like?',\n",
        "    'Tell me something interesting.',\n",
        "    'Who created you?',\n",
        "    'Do you dream of electric sheep?',\n",
        "    'Can you speak other languages?',\n",
        "    'What is machine learning?',\n",
        "    'Who won the World Cup in 2018?',\n",
        "    'What can you do?',\n",
        "    'Are you intelligent?',\n",
        "    'Do you have feelings?',\n",
        "    'What is the capital of France?',\n",
        "    'Who is the president of the United States?',\n",
        "    'What is the tallest mountain in the world?',\n",
        "    'How many continents are there?',\n",
        "    'What is the population of Earth?',\n",
        "    'Who wrote Hamlet?',\n",
        "    'What is quantum computing?',\n",
        "    'What is the speed of light?',\n",
        "    'Can you solve math problems?',\n",
        "    'What is your favorite movie?',\n",
        "]\n",
        "\n",
        "answers = [\n",
        "    'I am just a bot, but I am doing fine.',\n",
        "    'I am a chatbot created by OpenAI.',\n",
        "    'TensorFlow is a framework for building machine learning models.',\n",
        "    'Yes, Python is one of my favorite programming languages.',\n",
        "    'I do not have a favorite color. I am a bot.',\n",
        "    'Why don’t scientists trust atoms? Because they make up everything.',\n",
        "    'I am not sure, I do not have access to the current time.',\n",
        "    'Yes, Siri is another virtual assistant.',\n",
        "    'I cannot play music, but I can chat with you.',\n",
        "    'Boil water, then pour it over your tea. Steep for a few minutes.',\n",
        "    'I cannot check real-time data, including the weather.',\n",
        "    'The shortest war in history lasted 38 minutes.',\n",
        "    'I was created by developers using TensorFlow and Python.',\n",
        "    'I think about learning data patterns, not sheep.',\n",
        "    'Yes, but I am primarily programmed to respond in English.',\n",
        "    'Machine learning is a field of AI focused on teaching machines to learn from data.',\n",
        "    'France won the FIFA World Cup in 2018.',\n",
        "    'I can chat with you and answer questions to the best of my training.',\n",
        "    'My intelligence is artificial, designed by humans.',\n",
        "    'I do not have feelings. I process input and provide responses.',\n",
        "    'The capital of France is Paris.',\n",
        "    'As of my last update, please check the latest information online.',\n",
        "    'Mount Everest is considered the tallest mountain above sea level.',\n",
        "    'There are seven continents on Earth.',\n",
        "    'The Earth’s population is over 7 billion people.',\n",
        "    'William Shakespeare wrote Hamlet.',\n",
        "    'Quantum computing is computing using quantum-mechanical phenomena.',\n",
        "    'The speed of light is approximately 299,792 kilometers per second.',\n",
        "    'I can help solve simple math problems.',\n",
        "    'I do not watch movies, but I can discuss them based on my training data.',\n",
        "]\n",
        "\n",
        "conversations = [q + ', ' + a for q, a in zip(questions, answers)]\n",
        "print(conversations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_vy0EOV0x4F",
        "outputId": "5be42056-2815-45fb-caea-bafba1ed451b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "['How are you?, I am just a bot, but I am doing fine.', 'What is your name?, I am a chatbot created by OpenAI.', 'What is TensorFlow?, TensorFlow is a framework for building machine learning models.', 'Do you like Python?, Yes, Python is one of my favorite programming languages.', 'What is your favorite color?, I do not have a favorite color. I am a bot.', 'Tell me a joke., Why don’t scientists trust atoms? Because they make up everything.', 'What time is it?, I am not sure, I do not have access to the current time.', 'Do you know Siri?, Yes, Siri is another virtual assistant.', 'Can you play music?, I cannot play music, but I can chat with you.', 'How do I make tea?, Boil water, then pour it over your tea. Steep for a few minutes.', 'What’s the weather like?, I cannot check real-time data, including the weather.', 'Tell me something interesting., The shortest war in history lasted 38 minutes.', 'Who created you?, I was created by developers using TensorFlow and Python.', 'Do you dream of electric sheep?, I think about learning data patterns, not sheep.', 'Can you speak other languages?, Yes, but I am primarily programmed to respond in English.', 'What is machine learning?, Machine learning is a field of AI focused on teaching machines to learn from data.', 'Who won the World Cup in 2018?, France won the FIFA World Cup in 2018.', 'What can you do?, I can chat with you and answer questions to the best of my training.', 'Are you intelligent?, My intelligence is artificial, designed by humans.', 'Do you have feelings?, I do not have feelings. I process input and provide responses.', 'What is the capital of France?, The capital of France is Paris.', 'Who is the president of the United States?, As of my last update, please check the latest information online.', 'What is the tallest mountain in the world?, Mount Everest is considered the tallest mountain above sea level.', 'How many continents are there?, There are seven continents on Earth.', 'What is the population of Earth?, The Earth’s population is over 7 billion people.', 'Who wrote Hamlet?, William Shakespeare wrote Hamlet.', 'What is quantum computing?, Quantum computing is computing using quantum-mechanical phenomena.', 'What is the speed of light?, The speed of light is approximately 299,792 kilometers per second.', 'Can you solve math problems?, I can help solve simple math problems.', 'What is your favorite movie?, I do not watch movies, but I can discuss them based on my training data.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA PREPROCESSING\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(conversations)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create sequences\n",
        "sequences = []\n",
        "for conversation in conversations:\n",
        "    token_list = tokenizer.texts_to_sequences([conversation])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        sequences.append(n_gram_sequence)\n",
        "\n",
        "# Create sequences\n",
        "input_sequences = []\n",
        "for conversation in conversations:\n",
        "    token_list = tokenizer.texts_to_sequences([conversation])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences and create predictors and labels\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Predictors are all but the last word\n",
        "X = input_sequences[:,:-1]\n",
        "# Labels are the last word\n",
        "y = input_sequences[:,-1]\n",
        "\n",
        "# Now, ensure shapes match\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxOfnMxOPz_w",
        "outputId": "18b5d4b1-5b72-4a35-8276-4474e9eec153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (393, 19)\n",
            "Shape of y: (393,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL TRAINING\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 64, input_length=max_sequence_len-1, mask_zero=True),\n",
        "    LSTM(100),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])y\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9FIc3e7Q8Z-",
        "outputId": "b82d1242-86f0-4366-d019-a6b682e2d6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 8s 22ms/step - loss: 5.2754 - accuracy: 0.0356\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 5.2559 - accuracy: 0.0967\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 5.2073 - accuracy: 0.1018\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 5.0804 - accuracy: 0.0891\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 4.9627 - accuracy: 0.0865\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 4.8435 - accuracy: 0.0891\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 4.7235 - accuracy: 0.1018\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 4.5941 - accuracy: 0.0941\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 4.4734 - accuracy: 0.0916\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 4.3637 - accuracy: 0.1069\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 4.2622 - accuracy: 0.1018\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 4.1637 - accuracy: 0.1094\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 45ms/step - loss: 4.0519 - accuracy: 0.1120\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 3.9549 - accuracy: 0.1170\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 3.8583 - accuracy: 0.1272\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 3.7720 - accuracy: 0.1247\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 3.6788 - accuracy: 0.1399\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 3.5902 - accuracy: 0.1552\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 3.5306 - accuracy: 0.1578\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 50ms/step - loss: 3.4309 - accuracy: 0.1858\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 3.3475 - accuracy: 0.1934\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 40ms/step - loss: 3.2670 - accuracy: 0.2087\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 37ms/step - loss: 3.1743 - accuracy: 0.2290\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 3.0871 - accuracy: 0.2265\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 3.0015 - accuracy: 0.2468\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 2.9274 - accuracy: 0.2646\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 2.8483 - accuracy: 0.2774\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 2.7827 - accuracy: 0.3079\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 2.7157 - accuracy: 0.3155\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 2.6440 - accuracy: 0.3435\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 2.5682 - accuracy: 0.3639\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 2.5051 - accuracy: 0.3715\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 2.4371 - accuracy: 0.3969\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 1s 41ms/step - loss: 2.3751 - accuracy: 0.4275\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 2.3166 - accuracy: 0.4351\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 2.2494 - accuracy: 0.4606\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 2.1952 - accuracy: 0.4860\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 2.1371 - accuracy: 0.5013\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 2.0817 - accuracy: 0.5242\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 2.0258 - accuracy: 0.5471\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 1.9751 - accuracy: 0.5598\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 1.9244 - accuracy: 0.5827\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 1.8784 - accuracy: 0.5802\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 1.8225 - accuracy: 0.6234\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 1.7735 - accuracy: 0.6336\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 1.7286 - accuracy: 0.6590\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 1.6747 - accuracy: 0.6768\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 1.6277 - accuracy: 0.7201\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.5968 - accuracy: 0.7099\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 1.5591 - accuracy: 0.7277\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 39ms/step - loss: 1.5199 - accuracy: 0.7532\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 1.4799 - accuracy: 0.7583\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 1.4389 - accuracy: 0.7557\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 1.3932 - accuracy: 0.7863\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 35ms/step - loss: 1.3494 - accuracy: 0.7888\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 1.3200 - accuracy: 0.8092\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 34ms/step - loss: 1.2850 - accuracy: 0.8066\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 1s 38ms/step - loss: 1.2509 - accuracy: 0.8092\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 36ms/step - loss: 1.2227 - accuracy: 0.8168\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 1.1858 - accuracy: 0.8270\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.1528 - accuracy: 0.8397\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.1251 - accuracy: 0.8397\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 1.0957 - accuracy: 0.8524\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 1.0680 - accuracy: 0.8702\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 1.0428 - accuracy: 0.8651\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 1.0177 - accuracy: 0.8677\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.9920 - accuracy: 0.8728\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.9667 - accuracy: 0.8779\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.9438 - accuracy: 0.8906\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.9203 - accuracy: 0.8957\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.8940 - accuracy: 0.8957\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.8721 - accuracy: 0.8906\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.8535 - accuracy: 0.8906\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.8307 - accuracy: 0.8957\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.8096 - accuracy: 0.8957\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.7907 - accuracy: 0.9059\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.7704 - accuracy: 0.9033\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.7532 - accuracy: 0.9008\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.7350 - accuracy: 0.9033\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.7166 - accuracy: 0.9084\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.6994 - accuracy: 0.9059\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.6865 - accuracy: 0.9059\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.6748 - accuracy: 0.9084\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.6530 - accuracy: 0.9186\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.6408 - accuracy: 0.9211\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.6243 - accuracy: 0.9186\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.6113 - accuracy: 0.9160\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.5978 - accuracy: 0.9160\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.5851 - accuracy: 0.9211\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.5721 - accuracy: 0.9262\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 0.5604 - accuracy: 0.9262\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 1s 41ms/step - loss: 0.5475 - accuracy: 0.9211\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 1s 38ms/step - loss: 0.5363 - accuracy: 0.9211\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 37ms/step - loss: 0.5273 - accuracy: 0.9237\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 1s 39ms/step - loss: 0.5143 - accuracy: 0.9288\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 1s 40ms/step - loss: 0.5045 - accuracy: 0.9313\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.4928 - accuracy: 0.9313\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4825 - accuracy: 0.9313\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.4741 - accuracy: 0.9338\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 0.4655 - accuracy: 0.9364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a66d45df610>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CONVERSATIOn\n",
        "def generate_response(input_text):\n",
        "    # Initial setup\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    padded_input = pad_sequences(input_seq, maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted_word_index = model.predict(padded_input, verbose=0).argmax(axis=-1)\n",
        "\n",
        "    # Convert the predicted word index to a word\n",
        "    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n",
        "    return predicted_word\n",
        "\n",
        "# Taken from class repo\n",
        "print(\"Start chatting with the bot! Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    response = generate_response(user_input)\n",
        "    print(f\"Bot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXKCKGg2uzpd",
        "outputId": "591cfe1a-164d-40f0-bd56-cb27ea0e2ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start chatting with the bot! Type 'quit' to exit.\n",
            "Bot: wrote\n",
            "Bot: i\n",
            "Bot: wrote\n",
            "Bot: wrote\n",
            "Bot: the\n",
            "Bot: william\n"
          ]
        }
      ]
    }
  ]
}